{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e993a06",
   "metadata": {},
   "source": [
    "## Lat/Lon Matchups the Chlorophyll Rrs Data \n",
    "### HABs Group - West Coast\n",
    "* Keshav Dubedi\n",
    "* Bikas Gupta\n",
    "* Deborah Kutner\n",
    "* Mathieu Richaud\n",
    "* Dale Robinson\n",
    "##### PACE Hack Week, January 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb98d4c6",
   "metadata": {},
   "source": [
    "## Import libraries and set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ccc007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tqdm.auto\n",
    "# Kill all tqdm progress bars\n",
    "tqdm.auto.tqdm.disable = True\n",
    "# Silence earthaccess logs\n",
    "logging.getLogger(\"earthaccess\").setLevel(logging.ERROR)\n",
    "import earthaccess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccb177",
   "metadata": {},
   "source": [
    "## Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17449e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4ed122",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pace_file_finder(\n",
    "    start_time: str,\n",
    "    end_time: str,\n",
    "    short_id: str = \"PACE_OCI_L3M_CHL\",\n",
    "    granule_pattern: str = \"*.DAY.CHL.V3_1.chlor_a.4km.nc\",  # *.8D.CHL.V3_1.chlor_a.4km.nc\n",
    "):\n",
    "    \"\"\"\n",
    "    Find and open PACE OCI chlorophyll granules for a given date range.\n",
    "\n",
    "    Args:\n",
    "        start_time: ISO date string (YYYY-MM-DD).\n",
    "        end_time: ISO date string (YYYY-MM-DD).\n",
    "        short_id: Earthdata short name.\n",
    "        granule_pattern: Granule filename pattern.\n",
    "\n",
    "    Returns:\n",
    "        List of opened xarray datasets.\n",
    "    \"\"\"\n",
    "    results = earthaccess.search_data(\n",
    "        short_name=short_id,\n",
    "        temporal=(start_time, end_time),\n",
    "        granule_name=granule_pattern,\n",
    "    )\n",
    "    return earthaccess.open(results)\n",
    "\n",
    "\n",
    "def extract_mean_chl(\n",
    "    ds: xr.Dataset,\n",
    "    lat: float,\n",
    "    lon: float,\n",
    "    location_code: str,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Extract a directionally averaged chlorophyll value.\n",
    "\n",
    "    Args:\n",
    "        ds: Open PACE chlorophyll dataset.\n",
    "        lat: Target latitude.\n",
    "        lon: Target longitude.\n",
    "        location_code: Station identifier.\n",
    "\n",
    "    Returns:\n",
    "        Mean chlorophyll value or NaN.\n",
    "    \"\"\"\n",
    "    # Correct nearest-neighbor index lookup\n",
    "    lat_idx = int(np.abs(ds[\"lat\"].values - lat).argmin())\n",
    "    lon_idx = int(np.abs(ds[\"lon\"].values - lon).argmin())\n",
    "\n",
    "    ny = ds.sizes[\"lat\"]\n",
    "    nx = ds.sizes[\"lon\"]\n",
    "\n",
    "    def clip_slice(start, stop, maxval):\n",
    "        return slice(max(start, 0), min(stop, maxval))\n",
    "\n",
    "    if location_code in {\"SIO\", \"NP\"}:  # West\n",
    "        lat_slice = lat_idx\n",
    "        lon_slice = clip_slice(lon_idx - 8, lon_idx + 1, nx)\n",
    "\n",
    "    elif location_code in {\"CPP\", \"HAB_SCW\", \"SW\", \"TP\"}:  # South\n",
    "        lat_slice = clip_slice(lat_idx, lat_idx + 9, ny)\n",
    "        lon_slice = lon_idx\n",
    "\n",
    "    elif location_code == \"MB\":  # North\n",
    "        lat_slice = clip_slice(lat_idx - 8, lat_idx + 1, ny)\n",
    "        lon_slice = lon_idx\n",
    "\n",
    "    else:  # Southwest\n",
    "        lat_slice = clip_slice(lat_idx, lat_idx + 3, ny)\n",
    "        lon_slice = clip_slice(lon_idx - 2, lon_idx + 1, nx)\n",
    "\n",
    "    return (\n",
    "        ds[\"chlor_a\"]\n",
    "        .isel(lat=lat_slice, lon=lon_slice)\n",
    "        .mean(skipna=True)\n",
    "        .item()\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ba2fa",
   "metadata": {},
   "source": [
    "## Set up for matchup run\n",
    "* Set Directories\n",
    "* Login to earthaccess\n",
    "* Load in-situ data\n",
    "* Create place holder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = \"./calhabs_data.csv\"\n",
    "output_csv = \"./cal_habs_pace_chl_new_DAY1.csv\"\n",
    "earthaccess.login()\n",
    "\n",
    "df_insitu = pd.read_csv(input_csv)\n",
    "df = df_insitu[(df_insitu[\"date\"] >= \"2024-03-05\")].copy()\n",
    "\n",
    "df[\"chlor_a\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13dfdf",
   "metadata": {},
   "source": [
    "## Main download and processing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a8b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process once per unique date\n",
    "datasets_by_date: Dict[str, xr.Dataset] = {}\n",
    "\n",
    "for date, group in df.groupby(\"date\"):\n",
    "    logger.info(\"Processing date %s\", date)\n",
    "\n",
    "    files = pace_file_finder(date, date)\n",
    "    if not files:\n",
    "        logger.warning(\"No PACE data for %s\", date)\n",
    "        continue\n",
    "\n",
    "    with xr.open_dataset(files[0]) as ds:\n",
    "        for idx, row in group.iterrows():\n",
    "            try:\n",
    "                df.at[idx, \"chlor_a\"] = extract_mean_chl(\n",
    "                    ds,\n",
    "                    row[\"latitude\"],\n",
    "                    row[\"longitude\"],\n",
    "                    row[\"Location_Code\"],\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(\n",
    "                    \"Failed at %s (%s): %s\",\n",
    "                    row[\"Location_Code\"],\n",
    "                    date,\n",
    "                    e,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bfa438",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9bc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(output_csv, index=False)\n",
    "logger.info(\"Saved output to %s\", output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
