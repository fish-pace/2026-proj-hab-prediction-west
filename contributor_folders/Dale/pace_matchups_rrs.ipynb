{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc53b1f",
   "metadata": {},
   "source": [
    "## Lat/Lon/Time Matchups the PACE Rrs Data \n",
    "### HABs Group - West Coast\n",
    "* Keshav Dubedi\n",
    "* Bikas Gupta\n",
    "* Deborah Kutner\n",
    "* Mathieu Richaud\n",
    "* Dale Robinson\n",
    "##### PACE Hack Week, January 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db854f0c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59742c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import earthaccess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2f02f",
   "metadata": {},
   "source": [
    "## Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05731829",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"earthaccess\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc15ae2",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae258bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pace_rrs_file_finder(\n",
    "    start_time: str,\n",
    "    end_time: str,\n",
    "    short_id: str = \"PACE_OCI_L3M_RRS\",\n",
    "    granule_pattern: str = \"*.8D.RRS.V3_1.Rrs.4km.nc\",  # \"*.8D.RRS.V3_1.Rrs.4km.nc\"\n",
    "):\n",
    "    os.environ[\"EARTHACCESS_DISABLE_PROGRESS\"] = \"1\"\n",
    "    results = earthaccess.search_data(\n",
    "        short_name=short_id,\n",
    "        temporal=(start_time, end_time),\n",
    "        granule_name=granule_pattern\n",
    "    )\n",
    "    os.environ[\"EARTHACCESS_DISABLE_PROGRESS\"] = \"1\"\n",
    "    return earthaccess.open(results, pqdm_kwargs={\"disable\": True})\n",
    "\n",
    "\n",
    "def extract_mean_rrs(\n",
    "    ds: xr.Dataset,\n",
    "    lat: float,\n",
    "    lon: float,\n",
    "    location_code: str,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract directionally averaged Rrs spectrum (all wavelengths).\n",
    "\n",
    "    Returns:\n",
    "        1D numpy array: Rrs(wavelength)\n",
    "    \"\"\"\n",
    "    rrs = ds[\"Rrs\"]\n",
    "\n",
    "    lat_idx = int(np.abs(ds[\"lat\"].values - lat).argmin())\n",
    "    lon_idx = int(np.abs(ds[\"lon\"].values - lon).argmin())\n",
    "\n",
    "    ny = ds.sizes[\"lat\"]\n",
    "    nx = ds.sizes[\"lon\"]\n",
    "\n",
    "    def clip_slice(start, stop, maxval):\n",
    "        return slice(max(start, 0), min(stop, maxval))\n",
    "\n",
    "    if location_code in {\"SIO\", \"NP\"}:  # West\n",
    "        lat_sel = lat_idx\n",
    "        lon_sel = clip_slice(lon_idx - 8, lon_idx + 1, nx)\n",
    "\n",
    "    elif location_code in {\"CPP\", \"HAB_SCW\", \"SW\", \"TP\"}:  # South\n",
    "        lat_sel = clip_slice(lat_idx, lat_idx + 9, ny)\n",
    "        lon_sel = lon_idx\n",
    "\n",
    "    elif location_code == \"MB\":  # North\n",
    "        lat_sel = clip_slice(lat_idx - 8, lat_idx + 1, ny)\n",
    "        lon_sel = lon_idx\n",
    "\n",
    "    else:  # Southwest\n",
    "        lat_sel = clip_slice(lat_idx, lat_idx + 3, ny)\n",
    "        lon_sel = clip_slice(lon_idx - 2, lon_idx + 1, nx)\n",
    "\n",
    "    subset = rrs.isel(lat=lat_sel, lon=lon_sel)\n",
    "\n",
    "    # Average over spatial dims that remain\n",
    "    spatial_dims = [d for d in subset.dims if d in (\"lat\", \"lon\")]\n",
    "\n",
    "    mean_rrs = subset.mean(dim=spatial_dims, skipna=True)\n",
    "\n",
    "    return mean_rrs.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feb11af",
   "metadata": {},
   "source": [
    "## Set up for matchup run\n",
    "* Login to earthaccess\n",
    "* Load in-situ data\n",
    "* Create place holder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c061dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthaccess.login()\n",
    "\n",
    "df_insitu = pd.read_csv(\"calhabs_data.csv\")\n",
    "df = df_insitu[(df_insitu[\"date\"] >= \"2024-03-05\") & (df_insitu[\"date\"] <= \"2024-03-13\")].copy()\n",
    "\n",
    "# Placeholder â€” filled after first file\n",
    "rrs_columns = None\n",
    "rrs_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4433c",
   "metadata": {},
   "source": [
    "## Prime the columns for results dataframce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fdc0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file = None\n",
    "for date in df['date'].unique():\n",
    "    files = pace_rrs_file_finder(date, date)\n",
    "    if files:\n",
    "        first_file = files[0]\n",
    "        break\n",
    "\n",
    "if first_file:\n",
    "    with xr.open_dataset(first_file) as ds:\n",
    "        wavelengths = ds[\"wavelength\"].values\n",
    "        rrs_columns = [f\"rrs_{int(wl)}\" for wl in wavelengths]\n",
    "else:\n",
    "    logger.error(\"No PACE files found for any date. Cannot determine columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142d2d05",
   "metadata": {},
   "source": [
    "## Main download and processing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c320f058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 20:52:01,828 [INFO] Processing date 2024-03-06\n",
      "2026-01-29 20:52:16,157 [INFO] Processing date 2024-03-11\n",
      "2026-01-29 20:52:55,816 [INFO] Processing date 2024-03-13\n",
      "2026-01-29 20:52:59,269 [WARNING] No PACE Rrs data for 2024-03-13\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize rrs_columns early if possible, or handle the first-run case\n",
    "\n",
    "\n",
    "for date, group in df.groupby(\"date\"):\n",
    "    logger.info(\"Processing date %s\", date)\n",
    "\n",
    "    files = pace_rrs_file_finder(date, date)\n",
    "    \n",
    "    # ISSUE 1: Appending None causes the 'NoneType' error later\n",
    "    if not files:\n",
    "        logger.warning(\"No PACE Rrs data for %s\", date)\n",
    "        for _ in range(len(group)):\n",
    "            # If columns aren't known yet, we have to append a placeholder \n",
    "            # or handle this after the loop. \n",
    "            # If columns ARE known, use np.full(len(rrs_columns), np.nan)\n",
    "            rrs_data.append([np.nan] * (len(rrs_columns) if rrs_columns else 1)) \n",
    "        continue\n",
    "\n",
    "    with xr.open_dataset(files[0]) as ds:\n",
    "        ds = ds.sortby(\"lat\").sortby(\"lon\")\n",
    "\n",
    "        if rrs_columns is None:\n",
    "            wavelengths = ds[\"wavelength\"].values\n",
    "            rrs_columns = [f\"rrs_{int(wl)}\" for wl in wavelengths]\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            try:\n",
    "                spectrum = extract_mean_rrs(ds, row[\"latitude\"], row[\"longitude\"], row[\"Location_Code\"])\n",
    "                # Ensure spectrum is actually a list/array, not None\n",
    "                if spectrum is None:\n",
    "                    rrs_data.append([np.nan] * len(rrs_columns))\n",
    "                else:\n",
    "                    rrs_data.append(spectrum)\n",
    "            except Exception as e:\n",
    "                logger.error(\"Failed at %s (%s): %s\", row[\"Location_Code\"], date, e)\n",
    "                # ISSUE 2: If rrs_columns is None here, this will crash\n",
    "                fill_val = np.full(len(rrs_columns), np.nan) if rrs_columns else [np.nan]\n",
    "                rrs_data.append(fill_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2feb16",
   "metadata": {},
   "source": [
    "## Consolidate data and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrs_df = pd.DataFrame(rrs_data, columns=rrs_columns, index=df.index)\n",
    "\n",
    "df_out = pd.concat([df.reset_index(drop=True), rrs_df], axis=1)\n",
    "\n",
    "df_out.to_csv(\"cal_habs_pace_rrs_172band.csv\", index=False)\n",
    "\n",
    "logger.info(\"Saved Rrs output with %d bands\", len(rrs_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d0dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
